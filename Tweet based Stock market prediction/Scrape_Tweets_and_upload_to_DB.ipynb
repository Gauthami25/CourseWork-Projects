{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets for n no. of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "\n",
    "\n",
    "import sys\n",
    "old_stdout = sys.stdout\n",
    "\n",
    "log_file = open(\"message.log\",\"w\")\n",
    "\n",
    "sys.stdout = log_file\n",
    "\n",
    "tweets_list2 = []\n",
    "num_of_tweets = 5000\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "start_date = date(2020, 1, 1)\n",
    "end_date = date(2020, 1, 4)\n",
    "\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    \n",
    "    since_ = single_date.strftime(\"%Y-%m-%d\")\n",
    "    next_day = single_date + datetime.timedelta(days=1)\n",
    "    until_ = next_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(single_date.strftime(\"%Y-%m-%d\"),' to ', next_day.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    # since_ = '2020-01-01'\n",
    "    # until_ = '2020-01-02'\n",
    "\n",
    "    Apple_related_list = ['$Aapl', '$aapl', '@Apple', '#AAPL','@Aapl', '@apple', '#aapl']\n",
    "    # Apple_related_list = ['google', 'trump']\n",
    "    parsed_terms = []\n",
    "    for term in Apple_related_list:\n",
    "        parsed_terms.append(term)\n",
    "        if j <= num_of_tweets:\n",
    "            print('Working with {}'.format(term))\n",
    "            \n",
    "            for i,tweet in enumerate(sntwitter.TwitterSearchScraper('{} since:{} until:{}'.format(term, since_, until_)).get_items()):\n",
    "                if j>num_of_tweets:\n",
    "                    print('Got my {} tweets for date: {} from the term/terms: {}'.format(num_of_tweets, since_, parsed_terms))\n",
    "                    break\n",
    "                #if(tweet.user.verified == True and tweet.lang == 'en'):\n",
    "                if(tweet.lang == 'en'):\n",
    "                    j+=1\n",
    "                    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.retweetCount, tweet.lang, tweet.user.verified])\n",
    "                \n",
    "                \n",
    "    print('Final val of j: {}'.format(j))    \n",
    "    if(j < num_of_tweets):\n",
    "        print('Got {} tweets for date: {} from the term/terms: {}. Insufficient no. of valid Tweets!'.format(j, since_, parsed_terms))\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'Retweet_count', 'Language', 'Verified'])\n",
    "filename = 'SNS_scraped_tweets.csv'\n",
    "tweets_df2.to_csv(filename)\n",
    "\n",
    "sys.stdout = old_stdout\n",
    "\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push CSV data to Postgresql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "psycopg2.extensions.register_adapter(np.int64, psycopg2._psycopg.AsIs)\n",
    "psycopg2.extensions.register_adapter(np.bool_, psycopg2._psycopg.AsIs)\n",
    "\n",
    "# Initial DB table setup\n",
    "# Connecting to DB\n",
    "conn = psycopg2.connect(host = \"localhost\", database = \"my_first_local_db\", port = \"5432\", user = \"postgres\", password = \"Local\")\n",
    "\n",
    "# Table creation only if it doesen't exist already!\n",
    "# Tweet_Id should be unique, this prevent duplicate entries into the DB\n",
    "commands = (# Table 1         \n",
    "            '''Create Table IF NOT EXISTS Tweets_table(\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                date DATE,\n",
    "                tweet_Id BIGINT UNIQUE, \n",
    "                content TEXT,\n",
    "                user_Name TEXT,\n",
    "                retweet_Count BIGINT,  \n",
    "                language TEXT,\n",
    "                verified TEXT );''')\n",
    "\n",
    "# Creating a cursor to execute sql commands\n",
    "cur = conn.cursor()\n",
    "cur.execute(commands)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# Function to push rows to DB\n",
    "def dbconnect(date, tweet_id, content, user_name, retweet_count, language, verified):\n",
    "\n",
    "    conn = psycopg2.connect(host = \"localhost\", database = \"my_first_local_db\", port = \"5432\", user = \"postgres\", password = \"Local\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    command = '''INSERT INTO Tweets_table (date, tweet_id, content, user_name, retweet_count, language, verified) VALUES (%s, %s, %s, %s, %s, %s, %s) ON CONFLICT DO NOTHING;'''\n",
    "    cur.execute(command, (date, tweet_id, content, user_name, retweet_count, language, verified))\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "# reading the csv into pnadas df\n",
    "tweet_df = pd.read_csv(\"SNS_scraped_tweets.csv\")\n",
    "\n",
    "# Datetime\tTweet Id\tText\tUsername\tRetweet_count\tLanguage\tVerified\n",
    "for idx in tweet_df.index:\n",
    "    # read each row of csv and push it to DB\n",
    "    dbconnect(tweet_df['Datetime'][idx], tweet_df['Tweet Id'][idx], tweet_df['Text'][idx], tweet_df['Username'][idx], tweet_df['Retweet_count'][idx], tweet_df['Language'][idx], tweet_df['Verified'][idx] )\n",
    "    \n",
    "                \n",
    "             "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
